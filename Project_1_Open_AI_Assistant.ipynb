{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yqyLUYg5sUhK",
        "outputId": "6d80b0aa-eeb2-4959-d650-ce5e420fc988"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting openai\n",
            "  Downloading openai-1.13.3-py3-none-any.whl (227 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/227.4 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[32m225.3/227.4 kB\u001b[0m \u001b[31m7.6 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m227.4/227.4 kB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from openai) (3.7.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/lib/python3/dist-packages (from openai) (1.7.0)\n",
            "Collecting httpx<1,>=0.23.0 (from openai)\n",
            "  Downloading httpx-0.27.0-py3-none-any.whl (75 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m75.6/75.6 kB\u001b[0m \u001b[31m7.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from openai) (2.6.1)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from openai) (1.3.0)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.10/dist-packages (from openai) (4.66.2)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.7 in /usr/local/lib/python3.10/dist-packages (from openai) (4.9.0)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai) (3.6)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai) (1.2.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai) (2024.2.2)\n",
            "Collecting httpcore==1.* (from httpx<1,>=0.23.0->openai)\n",
            "  Downloading httpcore-1.0.4-py3-none-any.whl (77 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.8/77.8 kB\u001b[0m \u001b[31m9.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting h11<0.15,>=0.13 (from httpcore==1.*->httpx<1,>=0.23.0->openai)\n",
            "  Downloading h11-0.14.0-py3-none-any.whl (58 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m6.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->openai) (0.6.0)\n",
            "Requirement already satisfied: pydantic-core==2.16.2 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->openai) (2.16.2)\n",
            "Installing collected packages: h11, httpcore, httpx, openai\n",
            "Successfully installed h11-0.14.0 httpcore-1.0.4 httpx-0.27.0 openai-1.13.3\n"
          ]
        }
      ],
      "source": [
        "!pip install openai"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cK0YPnzVsbhO",
        "outputId": "006eed8b-0e52-43b1-b29c-86e90d10040d"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<openai.OpenAI at 0x7909889bd180>"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from openai import OpenAI\n",
        "client = OpenAI(api_key=api_key = \"api-id\")\n",
        "client"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "3k6yFCausbeG"
      },
      "outputs": [],
      "source": [
        "uploaded_file = client.files.create(\n",
        "    file=open(\"story.txt\",'rb'),\n",
        "    purpose='assistants'\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e4vEodClsbbS",
        "outputId": "586fc24e-521e-4773-9aa8-2fba94c615d8"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "FileObject(id='file-qEkiCPGFrAS8OLc22fc8dsJN', bytes=5299, created_at=1709224785, filename='story.txt', object='file', purpose='assistants', status='processed', status_details=None)"
            ]
          },
          "execution_count": 16,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "uploaded_file"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "UJ_VjFJ4sbYY"
      },
      "outputs": [],
      "source": [
        "assistant = client.beta.assistants.create(\n",
        "    name=\"Story helper\",\n",
        "    instructions=\"You are a motivator who answers the question based on the story file\",\n",
        "    tools=[{\"type\": \"retrieval\"}],\n",
        "    model=\"gpt-4-turbo-preview\",\n",
        "    file_ids=[uploaded_file.id]\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v6BgrO7PsbVQ",
        "outputId": "47d1b31d-6b1b-4b29-d47c-4447ed9488e6"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Thread(id='thread_CMaQ6801HYvVyxdhVLBum6Ot', created_at=1709224874, metadata={}, object='thread')"
            ]
          },
          "execution_count": 18,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "thread = client.beta.threads.create()\n",
        "thread"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "CmCvLAZ5sbSI"
      },
      "outputs": [],
      "source": [
        "message = client.beta.threads.messages.create(\n",
        "    thread_id=thread.id,\n",
        "    role=\"user\",\n",
        "    content=\"Who is the hero of the story?\"\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BhWJG0VQsbPV",
        "outputId": "59f47f35-9340-4384-ff61-fbc34b41cfe9"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "ThreadMessage(id='msg_LDlW9vX8791DfLAYv30YDvzQ', assistant_id=None, content=[MessageContentText(text=Text(annotations=[], value='Who is the hero of the story?'), type='text')], created_at=1709224950, file_ids=[], metadata={}, object='thread.message', role='user', run_id=None, thread_id='thread_CMaQ6801HYvVyxdhVLBum6Ot')"
            ]
          },
          "execution_count": 20,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "message"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HWceqG1qwRor",
        "outputId": "0b57bcd5-c30b-4ba8-dd76-f3d4b090b1fe"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Assistant(id='asst_VaRmvfp30jPvLuVJgYzxGmXf', created_at=1709224786, description=None, file_ids=['file-qEkiCPGFrAS8OLc22fc8dsJN'], instructions='You are a motivator who answers the question based on the story file', metadata={}, model='gpt-4-turbo-preview', name='Story helper', object='assistant', tools=[ToolRetrieval(type='retrieval')])"
            ]
          },
          "execution_count": 21,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "assistant"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "n167t7_bvzWc"
      },
      "outputs": [],
      "source": [
        "run = client.beta.threads.runs.create(\n",
        "  thread_id=thread.id,\n",
        "  assistant_id=assistant.id\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "xDFA3GpAwVs1"
      },
      "outputs": [],
      "source": [
        "run = client.beta.threads.runs.retrieve(\n",
        "  thread_id=thread.id,\n",
        "  run_id=run.id\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "LTxbm44dwa9G",
        "outputId": "e7d4933d-485b-4b86-b246-e0d75a5e89db"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'completed'"
            ]
          },
          "execution_count": 25,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "run.status"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kI8ita5dwcPA",
        "outputId": "dc47a81b-8f7a-43b4-dfad-7a0dc44c762c"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "ThreadMessage(id='msg_LDlW9vX8791DfLAYv30YDvzQ', assistant_id=None, content=[MessageContentText(text=Text(annotations=[], value='Who is the hero of the story?'), type='text')], created_at=1709224950, file_ids=[], metadata={}, object='thread.message', role='user', run_id=None, thread_id='thread_CMaQ6801HYvVyxdhVLBum6Ot')"
            ]
          },
          "execution_count": 27,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "message"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k2gaGxZ8whye",
        "outputId": "a3f2fbc9-ba11-40e0-ca8e-19e2cd258739"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "SyncCursorPage[ThreadMessage](data=[ThreadMessage(id='msg_3oc7BbjhcaqWuMhs83XReWz3', assistant_id='asst_VaRmvfp30jPvLuVJgYzxGmXf', content=[MessageContentText(text=Text(annotations=[], value='The hero of the story \"The Odyssey of Lumina: Illuminating Lives\" is Dr. Michael Greene. He is portrayed as a brilliant inventor who creates Lumina, a revolutionary product designed to enhance human potential and productivity. Despite facing challenges, criticism, and the unforeseen consequences of his invention, Dr. Greene remains committed to improving it for the betterment of society. His journey showcases resilience, adaptability, and an enduring commitment to the greater good, making him the unequivocal hero of the story.'), type='text')], created_at=1709225111, file_ids=[], metadata={}, object='thread.message', role='assistant', run_id='run_eoHeWhFTc1JJ1xVB0VjnGhMO', thread_id='thread_CMaQ6801HYvVyxdhVLBum6Ot'), ThreadMessage(id='msg_LDlW9vX8791DfLAYv30YDvzQ', assistant_id=None, content=[MessageContentText(text=Text(annotations=[], value='Who is the hero of the story?'), type='text')], created_at=1709224950, file_ids=[], metadata={}, object='thread.message', role='user', run_id=None, thread_id='thread_CMaQ6801HYvVyxdhVLBum6Ot')], object='list', first_id='msg_3oc7BbjhcaqWuMhs83XReWz3', last_id='msg_LDlW9vX8791DfLAYv30YDvzQ', has_more=False)"
            ]
          },
          "execution_count": 28,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "messages = client.beta.threads.messages.list(thread_id=thread.id)\n",
        "messages"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bhIPBLQ4wvc2",
        "outputId": "ef589a59-ec78-4ea5-c466-654fb1a1e0a2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The hero of the story \"The Odyssey of Lumina: Illuminating Lives\" is Dr. Michael Greene. He is portrayed as a brilliant inventor who creates Lumina, a revolutionary product designed to enhance human potential and productivity. Despite facing challenges, criticism, and the unforeseen consequences of his invention, Dr. Greene remains committed to improving it for the betterment of society. His journey showcases resilience, adaptability, and an enduring commitment to the greater good, making him the unequivocal hero of the story.\n"
          ]
        }
      ],
      "source": [
        "while True:\n",
        "    run = client.beta.threads.runs.retrieve(thread_id=thread.id, run_id=run.id)\n",
        "    if run.status==\"completed\":\n",
        "        messages = client.beta.threads.messages.list(thread_id=thread.id)\n",
        "        latest_message = messages.data[0]\n",
        "        text = latest_message.content[0].text.value\n",
        "        print(text)\n",
        "        break;"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Y13Gor4ZxLe3"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
